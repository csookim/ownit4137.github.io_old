---
title: "Do it! 딥러닝 입문 2"
date: 2020-07-30
categories: "MachineLearning" # 카테고리
excerpt: "로지스틱 회귀"
published : true # 공개

author_profile: false
header:
    teaser: "/assets/images/teaser/doitml.png"   # 작은 글일때의 이미지

toc: true #Table Of Contents 목차 보여줌
toc_label: " " # toc 이름 정의
toc_icon: " " #font Awesome아이콘으로 toc 아이콘 설정
toc_sticky: true # 스크롤 내릴때 같이 내려가는 목차
use_math: true # mathjax
---

# Code

{% highlight py %}
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np

cancer = load_breast_cancer()
x = cancer.data
y = cancer.target
{% endhighlight %}

## Cancer 자료 분석

{% highlight py %}
plt.boxplot(cancer.data)
cancer.feature_names[[3, 13, 23]] #indexing
  # result : array(['mean area', 'area error', 'worst area'], dtype='<U23')

np.unique(cancer.target, return_counts=True)
  # (array([0, 1]), array([212, 357]))
{% endhighlight %}


![](/assets/posts/ml/c4e59845.png)

- `boxplot` 함수를 이용해 data의 분포를 확인
- `feature_names` 함수를 이용해 분포가 큰 특성의 이름을 확인
- `unique` 함수를 이용해 들어있는 값의 종류와 횟수(return_counts = True)를 반환

## Dataset 분리

{% highlight py %}
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 42)
np.unique(y_train, return_counts = True)
  # (array([0, 1]), array([170, 285]))
{% endhighlight %}

- 데이터 세트를 training set와 test set으로 나눠줘야 함
- 데이터 세트의 클래스(종류) 비율이 유지되어야 함
- unique 함수를 이용해 비율이 유지됨을 확인(212:357 ≈ 170:285)

### train_test_split()

- `stratify = y` : 데이터 세트 클래스 비율을 유지함(y 에 target이 들어감)
- `test_size = 0.2` : test set의 비율을 의미, default는 0.25
- `random_state = 42` : 데이터 세트를 무작위로 섞을 때의 시드값, 값이 고정되면 set이 매번 동일하게 나옴


## class Neuron

{% highlight py %}
class LogisticNeuron:

  def __init__(self):
    self.w = None
    self.b = None

  # x(30, ) 와 w(30, ) 를 각각 곱하고 b를 더해 리턴
  def forpass(self, x):
    z = np.sum(x * self.w) + self.b
    return z

  # gradient 를 리턴
  def backprop(self, x, err):
    w_grad = x * err
    b_grad = 1 * err
    return w_grad, b_grad

  # logistic function
  def activation(self, z):
    a = 1 / (1 + np.exp(-z))
    return a

  def fit(self, x, y, epoch=100):
    self.w = np.ones(x.shape[1])
    self.b = 0
    for i in range(epoch):
      for x_i, y_i in zip(x, y):
        z = self.forpass(x_i)
        a = self.activation(z)
        err = -(y_i - a)
        w_grad, b_grad = self.backprop(x_i, err)
        self.w -= w_grad
        self.b -= b_grad

  """
  x_test(114, 30) 의 각 행을 forpass하여
  얻은 a(30, )값이 0.5보다 작은지(30, )를 리턴
  """
  def predict(self, x):
    z = [self.forpass(x_i) for x_i in x]
    a = self.activation(np.array(z))
    return a > 0.5
{% endhighlight %}


- 모든 y에 대해 `y_hat` 과 `y_i` 가 얼마나 차이가 있는지를 나타내는 것이 cost function($L$), 정의역은 w와 b
- cost 값을 최소로 만들기 위해 적절한 w와 b 탐색이 필요
- $L$을 w와 b에 대해 미분한 값을( `w_grad` , `b_grad` ) 업데이트 해줌으로써 gradient descent를 수행


{% highlight py %}
neuron = LogisticNeuron()
neuron.fit(x_train, y_train)
np.mean(neuron.predict(x_test) == y_test) # 0.825..
{% endhighlight %}

![](/assets/posts/ml/64c66e74.png)


## class SingleLayer

{% highlight py %}
class LogisticNeuron:

  def __init__(self):
    self.w = None
    self.b = None
    self.losses = []

  def forpass(self, x):
  def backprop(self, x, err):
  def activation(self, z):

  def fit(self, x, y, epoch=100):
    self.w = np.ones(x.shape[1])
    self.b = 0
    for e in range(epoch):
      loss = 0
      indexes = np.random.permutation(np.arange(len(x)))
      for i in indexes:
        z = self.forpass(x[i])
        a = self.activation(z)
        err = -(y[i] - a)
        w_grad, b_grad = self.backprop(x[i], err)
        self.w -= w_grad
        self.b -= b_grad
        a = np.clip(a, 1e-10, 1-1e-10)
        loss += -(y[i] * np.log(a) + (1-y[i]) * np.log(1-a))
      self.losses.append(loss/len(y))

  def predict(self, x):
    z = [self.forpass(x_i) for x_i in x]
    return np.array(z) > 0

  def score(self, x, y):
    return np.mean(self.predict(x) == y)
{% endhighlight %}

- `np.random.permutation(arr)` : arr의 무작위 순열을 리턴
- `np.arange(idx)` : 1부터 idx까지의 배열을 리턴
- `np.clip(var, l, r)` : var을 l과 r 사이로 limit
- `loss` : ith epoch 에서 각 데이터(row)의 손실 함숫값의 평균

{% highlight py %}
layer = SingleLayer()
layer.fit(x_train, y_train)
layer.score(x_test, y_test)

plt.plot(layer.losses)
plt.show()
{% endhighlight %}

![](/assets/posts/ml/cf2dc210.png)

- loss 값의 변화를 보여주는 그래프

## class SGDClassfier

- scikit-learn의 내장 클래스

{% highlight py %}
from sklearn.linear_model import SGDClassifier

sgd = SGDClassifier(loss='log', max_iter=100, tol=1e-3)
{% endhighlight %}

- `loss='log'` :  loss function의 종류를 지정(log, hinge, etc.)
- `max_iter=100` : 최대 반복 epoch 횟수, max_iter에 도달하면 경고가 발생
- `tol=1e-3` : max_iter번 반복되기 전에 손실 함숫값의 변화가 tol보다 작으면 반복을 중단

{% highlight py %}
sgd.fit(x_train, y_train)

print(sgd.score(x_test, y_test))
 # 0.8947368421052632

print(sgd.predict(x_test[0:10]), y_test[0:10])
 # [0 1 0 0 0 1 1 0 0 0] [0 1 0 1 0 1 1 0 0 0]
{% endhighlight %}

- predict 함수에 x_test 10개의 데이터(10, 30)를 넣고 예측한 값(10, )을 y_test(10, )와 비교
