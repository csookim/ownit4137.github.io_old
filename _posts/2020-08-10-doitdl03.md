---
title: "Do it! 딥러닝 입문 3"
date: 2020-08-10
categories: "MachineLearning" # 카테고리
excerpt: "BGD, Lasso, Ridge"
published : true # 공개

author_profile: false
header:
    teaser: "/assets/images/teaser/doitml.png"   # 작은 글일때의 이미지

toc: true #Table Of Contents 목차 보여줌
toc_label: " " # toc 이름 정의
toc_icon: " " #font Awesome아이콘으로 toc 아이콘 설정
toc_sticky: true # 스크롤 내릴때 같이 내려가는 목차
use_math: true # mathjax
---

# class SingleLayer

## 생성자, 학습

{% highlight py %}
import numpy as np

class SingleLayer:
  def __init__(self, learning_rate=0.1, l1=0, l2=0):
    self.w = None
    self.b = None
    self.losses = []  # train set에서의 손실 함숫값
    self.val_losses = []  # validation set에서의 손실 함숫값
    self.w_history = [] # epoch마다의 가중치
    self.lr = learning_rate # 학습률
    self.l1 = l1  # l1 계수
    self.l2 = l2  # l2 계수

  def forpass(self, x):
    z = np.dot(x, self.w) + self.b
    return z

  def backprop(self, x, err):
    m = len(x)
    w_grad = np.dot(x.T, err) / m
    b_grad = np.sum(err) / m
    return w_grad, b_grad

  def activation(self, z):
    a = 1 / (1 + np.exp(-z))
    return a

  def predict(self, x):
    z = self.forpass(x)
    return z > 0

  def score(self, x, y):  # 예측값과 target을 비교
    return np.mean(self.predict(x) == y.reshape(-1, 1))

{% endhighlight %}

### gradient 계산

계산한 a값과 y와의 차이(err)를 이용해 gradient를 계산.<br>
훈련 데이터 모두를 한꺼번에 계산하므로 각 $i$번째 데이터에서의 gradient가 모두 다르게 나옴.<br>
**각 $i$번째 gradient의 평균을 사용**<br><br>
$grad_i =  \dfrac{x^{(1)}_i e^{(1)}_i + x^{(2)}_i e^{(2)}_i +  \cdots  + x^{(m)}_i e^{(m)}_i }{m}  =  \dfrac{x^{T}_i E}{m}$
{: .notice}

## fit

{% highlight py %}
  def fit(self, x, y, epochs=100, x_val=None, y_val=None):
    y = y.reshape(-1, 1) # reshape -1
    y_val = y_val.reshape(-1, 1)
    m = len(x)
    self.w = np.ones((x.shape[1], 1))
    self.b = 0
    self.w_history.append(self.w.copy())

    for i in range(epochs):
      z = self.forpass(x)
      a = self.activation(z)
      err = -(y - a)
      w_grad, b_grad = self.backprop(x, err)
      w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m
      self.w -= self.lr * w_grad
      self.b -= self.lr * b_grad
      self.w_history.append(self.w.copy())
      a = np.clip(a, 1e-10, 1-1e-10)
      loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a)))
      self.losses.append((loss + self.reg_loss()) / m)
      self.update_val_loss(x_val, y_val)

  def reg_loss(self): # l1, l2 규제값
    return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)

  def update_val_loss(self, x_val, y_val):
    z = self.forpass(x_val)
    a = self.activation(z)
    a = np.clip(a, 1e-10, 1-1e-10)
    val_loss = np.sum(-(y_val * np.log(a) + (1 - y_val) * np.log(1 - a)))
    self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))
{% endhighlight %}

- `reshape(-1, k) or reshape(k, -1)` : 열(이나 행)을 k로 맞추고 행(이나 열)은 matrix에 맞게 자동설정
- backprop으로 로지스틱 손실 함수에서의 gradient를 계산하고 for문 내부 5번째 코드로 L1, L2 규제에서의 gradient를 계산함 (**왜 m으로 나누는지는 모름**)
- 로지스틱 손실 함숫값과 l1, l2 규제값(**왜 m으로 나누는지는 모름**)을 기록
- validation set에서의 손실 함숫값을 기록( `update_val_loss()` )

### L1 규제(Lasso)

- $\Vert w \Vert_{1} = \sum_{i=1}^n \vert w_{i} \vert$
- 손실 함수에 L1 penalty parameter `self.l1` 를 곱한 가중치 절댓값의 합을 추가하여 가중치를 규제

### L2 규제(Ridge)

- $\Vert w \Vert_{2} = \frac{1}{2} \sqrt{\sum_{i=1}^n {\vert w_{i} \vert}^2 }$
- 손실 함수에 L2 penalty parameter `self.l2` 를 곱한 루트 가중치 제곱합을 추가하여 가중치를 규제


## preprocessing  


{% highlight py %}
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

cancer = load_breast_cancer()
x = cancer.data
y = cancer.target

x_train_all, x_test, y_train_all, y_test
  = train_test_split(x, y, stratify = y, test_size = 0.2)
x_train, x_val, y_train, y_val
  = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2)

scaler = StandardScaler()
scaler.fit(x_train)

x_train_scaled = scaler.transform(x_train)
x_val_scaled = scaler.transform(x_val)
{% endhighlight %}

- `x(569, 30)` 를 `x_train(364, 30)` , `x_val(91, 30)` , `x_test(114, 30)`으로 나눔
- train_set의 모수들로 전처리하기 위해 fit을 사용
- **검증 세트를 훈련 세트와 같은 비율로 전처리해야 함**

## test

{% highlight py %}
single_layer = SingleLayer(l2 = 0.01)
single_layer.fit(x_train_scaled, y_train, x_val = x_val_scaled, y_val = y_val, epochs = 10000)
single_layer.score(x_val_scaled, y_val)
  # 0.978..
{% endhighlight %}

- epoch당 가중치의 업데이트가 한 번 일어나기 때문에 epoch를 크게 설정
- `x_train` 으로 학습시키고 `x_val` 로 확인


# BGD vs SGD



![](/assets/posts/ml/c804fcde.png)

It is essential to understand the difference between these optimization algorithms, as they compose a key function for Neural Networks. In summary, although Batch GD has higher accuracy than Stochastic GD, the latter is faster. The middle ground of the two and the most adopted, Mini-batch GD, combine both to deliver good accuracy and good performance. <br>Thus, the main difference between Batch, Mini-batch, and Stochastic Gradient Descent is the number of examples used for each epoch and the time and effort necessary to reach the global minimum value of the Cost Function.
{: .notice}

[Gradiend Descent Optimization Algs](http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html)
